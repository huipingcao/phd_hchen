{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1379)\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import json\n",
    "\n",
    "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
    "\n",
    "from src.clasp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "def load_floss_dataset(n_change_points=2):\n",
    "    desc_filename = \"datasets/FLOSS/desc.txt\"\n",
    "    desc_file = np.genfromtxt(fname=desc_filename, delimiter=',', filling_values=[None], dtype=None, encoding='utf8')\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for ts_name, window_size, floss_score, cp_1, cp_2 in desc_file:\n",
    "        if n_change_points == 1 and cp_2 != -1: continue\n",
    "\n",
    "        change_points = [cp_1]\n",
    "        if cp_2 != -1: change_points.append(cp_2)\n",
    "\n",
    "        ts = np.loadtxt(fname=os.path.join('datasets/FLOSS/', ts_name + '.txt'), dtype=np.float64)\n",
    "        df.append((ts_name, window_size, np.array(change_points), ts))\n",
    "\n",
    "    return pd.DataFrame.from_records(df, columns=[\"name\", \"window_size\", \"change points\", \"time_series\"])\n",
    "\n",
    "\n",
    "def load_ucrcp_dataset():\n",
    "    desc_filename = \"datasets/UCRCP/desc.txt\"\n",
    "    desc_file = []\n",
    "\n",
    "    with open(desc_filename, 'r') as file:\n",
    "        for line in file.readlines(): desc_file.append(line.split(\",\"))\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for row in desc_file:\n",
    "        (ts_name, window_size), change_points = row[:2], row[2:]\n",
    "\n",
    "        ts = np.loadtxt(fname=os.path.join('datasets/UCRCP/', ts_name + '.txt'), dtype=np.float64)\n",
    "        df.append((ts_name, int(window_size), np.array([int(_) for _ in change_points]), ts))\n",
    "\n",
    "    return pd.DataFrame.from_records(df, columns=[\"name\", \"window_size\", \"change points\", \"time_series\"])\n",
    "\n",
    "\n",
    "def load_combined_dataset():\n",
    "    return pd.concat([load_floss_dataset(), load_ucrcp_dataset()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floss_score(cps_true, cps_pred, ts_len):\n",
    "    assert len(cps_true) == len(cps_pred), \"true/predicted cps must have the same length.\"\n",
    "    differences = 0\n",
    "\n",
    "    for cp_pred in cps_pred:\n",
    "        distances = paired_euclidean_distances(\n",
    "            np.array([cp_pred]*len(cps_true)).reshape(-1,1),\n",
    "            cps_true.reshape(-1,1)\n",
    "        )\n",
    "        cp_true_idx = np.argmin(distances, axis=0)\n",
    "        cp_true = cps_true[cp_true_idx]\n",
    "        differences += np.abs(cp_pred-cp_true)\n",
    "\n",
    "    return np.round(differences / ts_len, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_comb = load_combined_dataset()\n",
    "\n",
    "    for idx, (name, window_size, cps, ts) in df_comb.iterrows():\n",
    "        if idx <1 :\n",
    "            runtime = time.process_time()\n",
    "            _, found_cps, _ = extract_clasp_cps(ts, window_size, len(cps))\n",
    "            runtime = np.round(time.process_time() - runtime, 6)\n",
    "\n",
    "            score = floss_score(cps, found_cps, ts.shape[0])\n",
    "            print(f\"Time Series: {name}: True Change Points: {cps}, Found Change Points: {found_cps}, Score: {score}, Runtime: {runtime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rolling distribution of distance for each window W_i to the last window W (to all left windows in TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1379)\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import json\n",
    "\n",
    "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
    "\n",
    "from src.clasp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_TCPD_dataset():\n",
    "    \"\"\" Load a TCPDBench dataset \"\"\"\n",
    "    desc_filename = \"datasets/TCPD/desc.txt\"\n",
    "    desc_file = []\n",
    "\n",
    "    with open(desc_filename, 'r') as file:\n",
    "        for line in file.readlines(): desc_file.append(line.split(\",\"))\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for row in desc_file:\n",
    "        (ts_name, window_size), change_points = row[:2], row[2:]\n",
    "\n",
    "        #ts = np.loadtxt(fname=os.path.join('datasets/UCRCP/', ts_name + '.txt'), dtype=np.float64)\n",
    "        filename = os.path.join('datasets/TCPD/', ts_name + '.json')\n",
    "        with open(filename, \"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        if data[\"time\"][\"index\"] != list(range(0, data[\"n_obs\"])):\n",
    "            raise NotImplementedError(\n",
    "                \"Time series with non-consecutive time axis are not yet supported.\"\n",
    "            )\n",
    "\n",
    "        mat = np.zeros((data[\"n_obs\"], data[\"n_dim\"]))\n",
    "        for j, series in enumerate(data[\"series\"]):\n",
    "            mat[:, j] = series[\"raw\"]\n",
    "        \n",
    "\n",
    "        # We normalize to avoid numerical errors.\n",
    "        mat = (mat - np.nanmean(mat)) / np.sqrt(np.nanvar(mat))\n",
    "        flatten_mat = [e for sublist in mat for e in sublist]\n",
    "        \n",
    "        df.append((ts_name, int(window_size), np.array([int(_) for _ in change_points]), flatten_mat))\n",
    "\n",
    "    return pd.DataFrame.from_records(df, columns=[\"name\", \"window_size\", \"change points\", \"time_series\"])\n",
    "\n",
    "df = load_TCPD_dataset()\n",
    "df_tcpd = df.iloc[0]['time_series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6],\n",
       "       [ 6, 10],\n",
       "       [10,  4],\n",
       "       [ 4,  7],\n",
       "       [ 7,  1],\n",
       "       [ 1, 19]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the sliding windows for a time series and a window size\n",
    "def sliding_window(ts, window_size):\n",
    "    shape = ts.shape[:-1] + (ts.shape[-1] - window_size + 1, window_size)\n",
    "    strides = ts.strides + (ts.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
    "ts = np.array([5, 6, 10, 4, 7, 1, 19])\n",
    "windows = sliding_window(ts, 2)\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_distance(W, Left):\n",
    "    \"\"\"\n",
    "    W: current window in TS\n",
    "    Left: Left part of W in TS\n",
    "    return: distance between current window and each previous window\n",
    "    \"\"\"\n",
    "    m = len(W)\n",
    "    n = len(Left)\n",
    "    prev_W = np.empty((len(Left) - m, m))\n",
    "    # calculte rolling distrubution \n",
    "    for i in range(m):\n",
    "        prev_W[:, i] = Left[i:i-m]\n",
    "    return np.linalg.norm(W - prev_W, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist_to_all_window_to_the_left(TS, m):\n",
    "    \"\"\"\n",
    "    TS: time series data\n",
    "    m: sliding window size\n",
    "    \"\"\"\n",
    "    # L - the number of time points in TS\n",
    "    L = len(TS) - m + 1\n",
    "    print('Length of TS: ', L)\n",
    "    # The distance matrix with size LxL\n",
    "    distance_arr = [] # array contatining distances\n",
    "    for i in range(L):\n",
    "        if i < m:\n",
    "            continue\n",
    "        # Current window (aka segment) - the last window maintaining\n",
    "        W = TS[i:i+m]\n",
    "        # Compute distance to every windows to its left, notice the index TS[:i]\n",
    "        distance_arr.append(sliding_distance(W, TS[:i]))\n",
    "    return distance_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k smallest elements: [1, 4, 5]\n",
      "index: [5, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "def find_k_smallest(ts,k):\n",
    "    res = sorted(ts)\n",
    "    index = sorted(range(len(ts)), key = lambda sub: arr[sub])[:k]\n",
    "    return res[:k],index\n",
    "ts = [5, 6, 10, 4, 7, 1, 19]\n",
    "k = 3\n",
    "res,index = find_k_smallest(ts,k)\n",
    "print('k smallest elements:', res)\n",
    "print('index:', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [6]\n",
      "Left: [0, 5, 1, 4, 4, 4]\n",
      "distance_W: [6. 1. 5. 2. 2.]\n",
      "k smallest elements: [1.0, 2.0, 2.0, 5.0, 6.0]\n",
      "index: [1, 3, 4, 2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 1.0, 3: 2.0, 4: 2.0, 2: 5.0, 0: 6.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_nearest_neighbors(TS, i, m, k):\n",
    "    \"\"\"\n",
    "    TS: the timeseries\n",
    "    i:  current window index\n",
    "    m: window size\n",
    "    k: number of nearest windows\n",
    "    return: an array consist of k nearest neighbors of window_i\n",
    "    \"\"\"\n",
    "    W = TS[i:i+m]\n",
    "    print('W:',W)\n",
    "    Left = TS[:i]\n",
    "    print('Left:',Left)\n",
    "    distance_W = sliding_distance(W, Left)\n",
    "    print('distance_W:', distance_W)\n",
    "    dist, index = find_k_smallest(distance_W, 5)\n",
    "    print('k smallest elements:', dist)\n",
    "    print('index:', index)\n",
    "    NNs = {i: j for i, j in zip(index, dist)}\n",
    "    return NNs\n",
    "TS = [0, 5, 1, 4, 4, 4, 6, 10, -2, 3]\n",
    "NNs = k_nearest_neighbors(TS, 6, 1, 2)\n",
    "NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_gap 3.0\n"
     ]
    }
   ],
   "source": [
    "def largest_gap(NNs):\n",
    "    \"\"\"\n",
    "    NNs: a list of index of k nearest windows to w_i\n",
    "    return: the largest consecutive gap\n",
    "    \"\"\"\n",
    "    distances = list(NNs.values())\n",
    "    gaps = []\n",
    "    for i in range(len(distances)-1):\n",
    "        gaps.append(abs(distances[i+1]-distances[i])) # try to avoid accessing by index in Python\n",
    "        \n",
    "    max_gap = max(gaps)\n",
    "    return max_gap\n",
    "print(\"max_gap:\", largest_gap(NNs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_gap_all_left_windows(TS, n_cps, k, window_size):\n",
    "    \"\"\"\n",
    "    TS: time series data\n",
    "    n_cps: the number of change points\n",
    "    k: k nearst neighbors\n",
    "    window_size: window size to slide windows\n",
    "    return: an array of largest gap for each window in TS\n",
    "    \"\"\"\n",
    "    # find KNNs for each window W based on distance_arr\n",
    "    \n",
    "    # calculate largest gap between KNNs and W\n",
    "    # find the n_cps largest gap from all windows\n",
    "    # Show the largest gap as a chart (like in clasp local maximum)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floss_data = load_floss_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "floss_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Powerdemand = floss_data[floss_data.name == 'Powerdemand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with Powerdemand dataset for pilot experiment\n",
    "Powerdemand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TS = Powerdemand['time_series'].values[0]\n",
    "print('Series data:', TS)\n",
    "w = Powerdemand.iloc[0]['window_size']\n",
    "print('Window size:', w)\n",
    "dist_arr = compute_dist_to_all_window_to_the_left(TS, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the distribution of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_as_histogram(ax, data, bins):\n",
    "    # data: a list of number\n",
    "    # bins: number of bins in histogram\n",
    "    ax.hist(data, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_a_random_window(ts, cp):\n",
    "    x = random.choice(range(len(dist_arr)))\n",
    "    while x >= cp[0] and x <= cp[-1]:\n",
    "        x = random.choice(range(len(dist_arr)))\n",
    "    return ts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulize windows where change points are located\n",
    "change_point_window1 = dist_arr[4498]\n",
    "change_point_window2 = dist_arr[4499]\n",
    "change_point_window3 = dist_arr[4500]\n",
    "change_point_window4 = dist_arr[4501]\n",
    "change_point_window5 = dist_arr[4502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=5, figsize=(30, 10))\n",
    "\n",
    "visualize_as_histogram(axes[0], change_point_window1, 100)\n",
    "visualize_as_histogram(axes[1], change_point_window2, 100)\n",
    "visualize_as_histogram(axes[2], change_point_window3, 100)\n",
    "visualize_as_histogram(axes[3], change_point_window4, 100)\n",
    "visualize_as_histogram(axes[4], change_point_window5, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = [4498, 4499, 4500, 4501, 4502]\n",
    "fig, axes = plt.subplots(ncols=5, nrows=3, figsize=(30, 30))\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[0][0], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[0][1], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[0][2], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[0][3], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[0][4], w, 100)\n",
    "\n",
    "########################################\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[1][0], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[1][1], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[1][2], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[1][3], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[1][4], w, 100)\n",
    "\n",
    "#################################3\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[2][0], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[2][1], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[2][2], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[2][3], w, 100)\n",
    "\n",
    "w = select_a_random_window(dist_arr, cps)\n",
    "visualize_as_histogram(axes[2][4], w, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
