{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1379)\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import json\n",
    "\n",
    "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
    "\n",
    "from src.clasp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_TCPD_dataset():\n",
    "    \"\"\" Load a TCPDBench dataset \"\"\"\n",
    "    desc_filename = \"datasets/TCPD/desc.txt\"\n",
    "    desc_file = []\n",
    "\n",
    "    with open(desc_filename, 'r') as file:\n",
    "        for line in file.readlines(): desc_file.append(line.split(\",\"))\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for row in desc_file:\n",
    "        (ts_name, window_size), change_points = row[:2], row[2:]\n",
    "\n",
    "        #ts = np.loadtxt(fname=os.path.join('datasets/UCRCP/', ts_name + '.txt'), dtype=np.float64)\n",
    "        filename = os.path.join('datasets/TCPD/', ts_name + '.json')\n",
    "        with open(filename, \"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        if data[\"time\"][\"index\"] != list(range(0, data[\"n_obs\"])):\n",
    "            raise NotImplementedError(\n",
    "                \"Time series with non-consecutive time axis are not yet supported.\"\n",
    "            )\n",
    "\n",
    "        mat = np.zeros((data[\"n_obs\"], data[\"n_dim\"]))\n",
    "        for j, series in enumerate(data[\"series\"]):\n",
    "            mat[:, j] = series[\"raw\"]\n",
    "        \n",
    "\n",
    "        # We normalize to avoid numerical errors.\n",
    "        mat = (mat - np.nanmean(mat)) / np.sqrt(np.nanvar(mat))\n",
    "        flatten_mat = [e for sublist in mat for e in sublist]\n",
    "        \n",
    "        df.append((ts_name, int(window_size), np.array([int(_) for _ in change_points]), flatten_mat))\n",
    "\n",
    "    return pd.DataFrame.from_records(df, columns=[\"name\", \"window_size\", \"change points\", \"time_series\"])\n",
    "\n",
    "\n",
    "def load_sample_series():\n",
    "    df = load_TCPD_dataset()\n",
    "    #for idx, (name, window_size, cps, ts) in df.iterrows():\n",
    "    df_sample = df[:1]\n",
    "    #print('Sample dataset:', df_sample)\n",
    "    ts_sample = df_sample.iloc[0]['time_series']\n",
    "    #print('Sample series:', ts_sample)\n",
    "    w_size_sample = df_sample.iloc[0]['window_size']\n",
    "    #print('Sample window_size:', w_size_sample)\n",
    "    n_cps_sample = df_sample.iloc[0]['change points']\n",
    "    #print('Sample change points:', n_cps_sample)\n",
    "    return ts_sample, w_size_sample, n_cps_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding windows and mean, std, dotProduct calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sliding windows for a time series and a window size\n",
    "def sliding_window(ts, window_size):\n",
    "    shape = ts.shape[:-1] + (ts.shape[-1] - window_size + 1, window_size)\n",
    "    strides = ts.strides + (ts.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
    "\n",
    "# the sliding mean and std for a time series and a window size\n",
    "def sliding_mean_std(TS, m):\n",
    "    s = np.insert(np.cumsum(TS), 0, 0)\n",
    "    sSq = np.insert(np.cumsum(TS ** 2), 0, 0)\n",
    "    segSum = s[m:] - s[:-m]\n",
    "    segSumSq = sSq[m:] - sSq[:-m]\n",
    "    movmean = segSum / m\n",
    "    movstd = np.sqrt(segSumSq / m - (segSum / m) ** 2)\n",
    "    return [movmean, movstd]\n",
    "\n",
    "# the sliding dot product between a query subsequence and a time series\n",
    "def slidingDotProduct(query, ts):\n",
    "    m = len(query)\n",
    "    n = len(ts)\n",
    "\n",
    "    ts_add = 0\n",
    "    if n % 2 == 1:\n",
    "        ts = np.insert(ts, 0, 0)\n",
    "        ts_add = 1\n",
    "\n",
    "    q_add = 0\n",
    "    if m % 2 == 1:\n",
    "        query = np.insert(query, 0, 0)\n",
    "        q_add = 1\n",
    "\n",
    "    query = query[::-1]\n",
    "    query = np.pad(query, (0, n - m + ts_add - q_add), 'constant')\n",
    "    trim = m - 1 + ts_add\n",
    "    dot_product = fft.irfft(fft.rfft(ts) * fft.rfft(query))\n",
    "    return dot_product[trim:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kNN indices with dot-product / no-loops for a time series, a window size and k neighbours\n",
    "def compute_distances_iterative(TS, m, k):\n",
    "    l = len(TS) - m + 1\n",
    "    knns = np.zeros(shape=(l, k), dtype=np.int64)\n",
    "    knns_distance = np.zeros(shape=(l, k), dtype=np.int64)\n",
    "\n",
    "    dot_prev = None\n",
    "    means, stds = sliding_mean_std(TS, m)\n",
    "\n",
    "    for order in range(0, l):\n",
    "        # first iteration O(n log n)\n",
    "        if order == 0:\n",
    "            dot_first = slidingDotProduct(TS[:m], TS)\n",
    "            # dot_first = np.dot(X[order,:], X.T)\n",
    "            dot_rolled = dot_first\n",
    "        # O(1) further operations\n",
    "        else:\n",
    "            dot_rolled = np.roll(dot_prev, 1) + TS[order + m - 1] * TS[m - 1:l + m] - TS[order - 1] * np.roll(TS[:l], 1)\n",
    "            dot_rolled[0] = dot_first[order]\n",
    "\n",
    "        x_mean = means[order]\n",
    "        x_std = stds[order]\n",
    "\n",
    "        dist = 2 * m * (1 - (dot_rolled - m * means * x_mean) / (m * stds * x_std))\n",
    "#         print('dist:', dist)\n",
    "        \n",
    "        # self-join: exclusion zone\n",
    "        trivialMatchRange = (int(max(0, order - np.round(m / 2, 0))), int(min(order + np.round(m / 2 + 1, 0), l)))\n",
    "        dist[trivialMatchRange[0]:trivialMatchRange[1]] = np.inf\n",
    "        #print('dist:', dist)\n",
    "        \n",
    "        idx = np.argpartition(dist, k)\n",
    "        #print('idx:', idx)\n",
    "\n",
    "        knns[order, :] = idx[:k]\n",
    "#         knns_distance[order, :] = dist[:k]\n",
    "        dot_prev = dot_rolled\n",
    "#     print('dist', dist)\n",
    "#     print('idx', idx)\n",
    "#     print('knns:', knns)\n",
    "#     print('knns_distance:', knns_distance)\n",
    "    return knns\n",
    "    \n",
    "def compute_distances_windows(ts, w_size, k):\n",
    "    KNNs = []\n",
    "    for i in range(k, len(ts)-w_size+1):\n",
    "        #print(np.array(ts[:w_size+i]))\n",
    "        KNNs.append(compute_distances_iterative(ts[:w_size+i], w_size, k))\n",
    "    #print(KNNs)\n",
    "    return KNNs\n",
    "\n",
    "# ts =  np.array([0, 5, 1, 4, 10, -2, 3, 8, 7, 9, 2])\n",
    "# ts_small = np.array([0, 5, 1, 10, -2, 7, 8])\n",
    "# w_size = 3\n",
    "# k = 3\n",
    "# knns = compute_distances_iterative(ts_small, w_size, k)\n",
    "# compute_distances_windows(ts_small, w_size, k)\n",
    "\n",
    "def majority_knns(ts, w_size, knns, k):\n",
    "    \n",
    "    return majority_knns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum gap calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distance_by_idx(TS, w_size, idx):\n",
    "    sliding_mean_std(TS, w_size)\n",
    "    means, stds = sliding_mean_std(TS, w_size)\n",
    "    mean_idx = []\n",
    "    std_idx = []\n",
    "    for i in idx:\n",
    "        mean_idx.append(means[i])\n",
    "        std_idx.append(stds[i])\n",
    "    return mean_idx, std_idx\n",
    "\n",
    "        \n",
    "def largest_gap(NNs):\n",
    "    \"\"\"find consecutive difference\"\"\"\n",
    "    #differences = list(NNs.values())\n",
    "    gaps = np.diff(NNs)\n",
    "    #print('gaps:', gaps)\n",
    "    abs_gaps = [abs(e) for e in gaps]\n",
    "    print('abs_gaps:', abs_gaps)\n",
    "    \"\"\"here we find the maximum value of an nd-array\"\"\"\n",
    "    max_gap = np.amax(abs_gaps)\n",
    "    return max_gap    \n",
    "\n",
    "def extract_largest_gap_for_all_windows_from_knns(ts, knns):\n",
    "    max_gaps = []\n",
    "    for idx in knns:\n",
    "        #print('idx:', idx)\n",
    "        mean_idx, std_idx = extract_distance_by_idx(ts, w_size, idx)\n",
    "        mean_idx.append(mean_idx[0])\n",
    "        max_gap = largest_gap(mean_idx)\n",
    "        max_gaps.append(max_gap)\n",
    "        print('mean_idx:', mean_idx)\n",
    "        #print('std_idx:', std_idx)\n",
    "        #print('max_gap:', max_gap)\n",
    "    return max_gaps\n",
    "# max_gaps = extract_largest_gap_for_all_windows_from_knns(knns)\n",
    "# print('max_gaps:', max_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with real data (TCPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts size: 313\n"
     ]
    }
   ],
   "source": [
    "ts, w_size, n_cps = load_sample_series()\n",
    "print('ts size:', len(ts))\n",
    "ts = np.array(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNs in total: 6\n",
      "head KNNs: [array([[0, 3, 2],\n",
      "       [0, 1, 3],\n",
      "       [0, 1, 2],\n",
      "       [0, 1, 2]]), array([[3, 2, 4],\n",
      "       [3, 4, 0],\n",
      "       [3, 4, 0],\n",
      "       [3, 0, 2],\n",
      "       [1, 0, 2]]), array([[3, 5, 2],\n",
      "       [3, 5, 4],\n",
      "       [4, 5, 0],\n",
      "       [0, 5, 3],\n",
      "       [4, 0, 1],\n",
      "       [2, 0, 1]]), array([[6, 3, 5],\n",
      "       [4, 3, 5],\n",
      "       [4, 6, 5],\n",
      "       [0, 6, 5],\n",
      "       [1, 0, 6],\n",
      "       [2, 0, 1],\n",
      "       [2, 0, 3]]), array([[6, 3, 5],\n",
      "       [4, 7, 5],\n",
      "       [5, 7, 6],\n",
      "       [5, 0, 6],\n",
      "       [1, 7, 0],\n",
      "       [2, 7, 0],\n",
      "       [2, 0, 3],\n",
      "       [2, 1, 4]]), array([[3, 6, 8],\n",
      "       [5, 4, 7],\n",
      "       [7, 5, 6],\n",
      "       [8, 0, 6],\n",
      "       [1, 8, 7],\n",
      "       [2, 7, 0],\n",
      "       [3, 0, 2],\n",
      "       [1, 4, 2],\n",
      "       [3, 0, 4]])]\n",
      "abs_gaps: [array([2., 1.]), array([1.33333333, 0.66666667]), array([1.33333333, 1.66666667]), array([1.33333333, 1.66666667]), array([2., 1.])]\n",
      "abs_gaps: [array([1.        , 1.33333333]), array([0.33333333, 1.66666667]), array([0.33333333, 1.66666667]), array([2., 3.]), array([1.33333333, 3.        ]), array([1.        , 1.33333333])]\n",
      "abs_gaps: [array([1., 2.]), array([1.        , 0.66666667]), array([0.66666667, 1.        ]), array([1., 1.]), array([1.66666667, 1.33333333]), array([3.        , 1.33333333]), array([1., 2.])]\n",
      "abs_gaps: [array([2., 1.]), array([0.33333333, 1.        ]), array([2.33333333, 3.        ]), array([4., 3.]), array([1.33333333, 4.        ]), array([3.        , 1.33333333]), array([3., 2.]), array([2., 1.])]\n",
      "abs_gaps: [array([2., 1.]), array([4.33333333, 5.        ]), array([5., 2.]), array([1., 4.]), array([4.66666667, 6.        ]), array([3., 6.]), array([3., 2.]), array([1.66666667, 0.33333333]), array([2., 1.])]\n",
      "abs_gaps: [array([2., 0.]), array([0.66666667, 4.33333333]), array([5., 3.]), array([4., 4.]), array([2.66666667, 2.        ]), array([3., 6.]), array([2., 3.]), array([0.33333333, 1.33333333]), array([2.        , 1.66666667]), array([2., 0.])]\n",
      "max_gaps: [2.0, 3.0, 3.0, 4.0, 6.0, 6.0]\n"
     ]
    }
   ],
   "source": [
    "ts =  np.array([0, 5, 1, 4, 10, -2, 3, 8, 7, 9, 2])\n",
    "ts_small = np.array([0, 5, 1, 10, -2, 7, 8])\n",
    "w_size = 3\n",
    "k = 3\n",
    "\n",
    "KNNs = compute_distances_windows(ts, w_size, k)\n",
    "print('KNNs in total:', len(KNNs))\n",
    "print('head KNNs:', KNNs)\n",
    "max_gaps = extract_largest_gap_for_all_windows_from_knns(ts, KNNs)\n",
    "print('max_gaps:', max_gaps)\n",
    "\n",
    "# Plot max_gaps\n",
    "# plt.plot(range(len(max_gaps)), max_gaps)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
